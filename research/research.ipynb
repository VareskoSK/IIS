{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Selling_Price</th>\n",
       "      <th>Driven_kms</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Selling_type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner</th>\n",
       "      <th>Age_of_car</th>\n",
       "      <th>Car_depreciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.208960</td>\n",
       "      <td>27000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.558145</td>\n",
       "      <td>43000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.981001</td>\n",
       "      <td>6900</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.047319</td>\n",
       "      <td>5200</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.526056</td>\n",
       "      <td>42450</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2.251292</td>\n",
       "      <td>33988</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1.386294</td>\n",
       "      <td>60000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1.208960</td>\n",
       "      <td>87934</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2.442347</td>\n",
       "      <td>9000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1.667707</td>\n",
       "      <td>5464</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Selling_Price  Driven_kms Fuel_Type Selling_type Transmission  Owner  \\\n",
       "0         1.208960       27000    Petrol       Dealer       Manual      0   \n",
       "1         1.558145       43000    Diesel       Dealer       Manual      0   \n",
       "2         1.981001        6900    Petrol       Dealer       Manual      0   \n",
       "3         1.047319        5200    Petrol       Dealer       Manual      0   \n",
       "4         1.526056       42450    Diesel       Dealer       Manual      0   \n",
       "..             ...         ...       ...          ...          ...    ...   \n",
       "296       2.251292       33988    Diesel       Dealer       Manual      0   \n",
       "297       1.386294       60000    Petrol       Dealer       Manual      0   \n",
       "298       1.208960       87934    Petrol       Dealer       Manual      0   \n",
       "299       2.442347        9000    Diesel       Dealer       Manual      0   \n",
       "300       1.667707        5464    Petrol       Dealer       Manual      0   \n",
       "\n",
       "     Age_of_car  Car_depreciation  \n",
       "0            11             4.381  \n",
       "1            12             7.982  \n",
       "2             8             7.869  \n",
       "3            14             3.103  \n",
       "4            11             5.344  \n",
       "..          ...               ...  \n",
       "296           9             9.349  \n",
       "297          10             4.514  \n",
       "298          16             9.791  \n",
       "299           8            10.058  \n",
       "300           9             4.232  \n",
       "\n",
       "[299 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# импортируем чистый датасет из лр1\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('/Users/sergejvaresko/iis_proj/data/clean_dataset.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разделение на тестовую и обучающую выборки в размере 25%-75%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка содержит (224, 7)\n",
      "Тестовая выборка содержит (75, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('Selling_Price', axis = 1) # данные для регрессии, без целевой переменной\n",
    "y = data['Selling_Price'] # целевая переменная (по которой потом будет сравнение)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)\n",
    "\n",
    "print(f\"Обучающая выборка содержит {X_train.shape}\")\n",
    "\n",
    "print(f\"Тестовая выборка содержит {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создаем переменные для хранения имен столбцов категориальных и числовых переменных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Driven_kms            int64\n",
       "Fuel_Type            object\n",
       "Selling_type         object\n",
       "Transmission         object\n",
       "Owner                 int64\n",
       "Age_of_car            int64\n",
       "Car_depreciation    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовые признаки находятся в столбцах - ['Driven_kms', 'Owner', 'Age_of_car', 'Car_depreciation']\n",
      "Категориальные признаки находятся в столбцах - ['Fuel_Type', 'Selling_type', 'Transmission']\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.to_list()\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns.to_list()\n",
    "\n",
    "print(f\"Числовые признаки находятся в столбцах - {numeric_columns}\")\n",
    "print(f\"Категориальные признаки находятся в столбцах - {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание pipeline обработки признаков и обучения модели. Для числовых признаков используется StandardScaler, для категориальных - OrdinalEncoder для задачи регрессии. В качестве модели - RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "preprocessor_data = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', StandardScaler(), numeric_columns),\n",
    "            ('categorical', OrdinalEncoder(), categorical_columns)\n",
    "        ]\n",
    ")\n",
    "\n",
    "pipeline_model = Pipeline([\n",
    "    ('preprocessor', preprocessor_data),\n",
    "    ('regressor',RandomForestRegressor(random_state=42))\n",
    "                ])\n",
    "\n",
    "# param = {\n",
    "#     'regressor__n_estimators' : [50, 100, 150, 200],\n",
    "#     'regressor__max_depth' : [None, 10, 20, 25]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучить модель и получить на тестовой выборке метрики качества**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline модель:\n",
      "MAE: 0.35\n",
      "MAPE: 3740736895105443.00%\n",
      "MSE: 0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "model_1v = pipeline_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание\n",
    "y_pred_baseline = pipeline_model.predict(X_test)\n",
    "\n",
    "# Метрики\n",
    "mae = mean_absolute_error(y_test, y_pred_baseline)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred_baseline)\n",
    "mse = mean_squared_error(y_test, y_pred_baseline)\n",
    "\n",
    "print(\"Baseline модель:\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MAPE: {mape:.2%}\")\n",
    "print(f\"MSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**http://127.0.0.1:5000 - адрес для MLFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание артефактов и логирование первой модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 00:55:43 INFO mlflow.tracking.fluent: Experiment with name 'Baseline_Experiment_1' does not exist. Creating a new experiment.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\")\n",
    "\n",
    "# Можно создать эксперимент вручную с артефактами:\n",
    "if not mlflow.get_experiment_by_name(\"Baseline_Experiment_1\"):\n",
    "    mlflow.create_experiment(\n",
    "        name=\"Baseline_Experimen_1\",\n",
    "        artifact_location=\"file:///Users/sergejvaresko/iis_proj/mlflow/mlruns_artifacts\"\n",
    "    )\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"Baseline_Experiment_1\")\n",
    "\n",
    "input_example = X_train.head(5)\n",
    "signature = infer_signature(X_train.head(5), pipeline_model.predict(X_train.head(5)))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model_type\", \"baseline\")\n",
    "    mlflow.set_tag(\"framework\", \"sklearn\")\n",
    "\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline_model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1744236150877, current_stage='None', description=None, last_updated_timestamp=1744236150877, name='BaselineRandomForest', run_id='ea9f8aa3085a46bc9afcb04053ab15b8', run_link=None, source='runs:/ea9f8aa3085a46bc9afcb04053ab15b8/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "run_id = \"ea9f8aa3085a46bc9afcb04053ab15b8\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model_name = \"BaselineRandomForest\"\n",
    "client.create_registered_model(model_name)\n",
    "client.create_model_version(name=model_name, source=model_uri, run_id=run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пункт 10 Создаем новый экс и логируем все**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте новую переменную X_train_fe_sklearn- копию исходной обучающей выборки, используя метод .copy() датафрейма. - готово\n",
    "\n",
    "Создайте ColumnTransformer, содержащий как трансформации baseline-модели (сделанные ранее), так и новые. - готово\n",
    "\n",
    "Обучите и сохраните в переменную X_train_fe_sklearn (используя метод fit_transform) получившиеся преобразования. - готово\n",
    "\n",
    "Сохраните в файл названия столбцов получившегося датафрейма. Этот файл нужно будет залогировать в MLFlow - готово\n",
    "\n",
    "Создайте pipeline, в котором на первом шаге будет работать ColumnTransformer, созданный в этом пункте, а на втором - модель. - готово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "2025/04/10 15:30:51 INFO mlflow.tracking.fluent: Experiment with name 'Feature_Engineering_Experiment' does not exist. Creating a new experiment.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, PolynomialFeatures, KBinsDiscretizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "\n",
    "X_train_fe_sklearn = X_train.copy()\n",
    "\n",
    "poly_features = ['Driven_kms', 'Age_of_car']\n",
    "bin_features = ['Car_depreciation', 'Owner']\n",
    "cat_features = ['Fuel_Type', 'Selling_type', 'Transmission']\n",
    "all_num = X_train_fe_sklearn.select_dtypes(include=['int64', 'float64']).columns.tolist() #отберем еще раз тк выборку копировали, для сохранности пред экс\n",
    "base_num = list(set(all_num) - set(poly_features) - set(bin_features))\n",
    "\n",
    "\n",
    "poly_transformer = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "bin_transformer = Pipeline([\n",
    "    (\"kbins\", KBinsDiscretizer(n_bins=4, encode='onehot-dense', strategy='quantile'))\n",
    "])\n",
    "\n",
    "base_transformer = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    (\"ordinal\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "\n",
    "full_preprocessor = ColumnTransformer([\n",
    "    (\"poly_features\", poly_transformer, poly_features),\n",
    "    (\"bin_features\", bin_transformer, bin_features),\n",
    "    (\"base_numeric\", base_transformer, base_num),\n",
    "    (\"categorical\", cat_transformer, cat_features)\n",
    "])\n",
    "\n",
    "\n",
    "X_train_fe_transformed = full_preprocessor.fit_transform(X_train_fe_sklearn)\n",
    "\n",
    "poly_names = full_preprocessor.named_transformers_['poly_features']['poly'].get_feature_names_out(poly_features)\n",
    "bin_names = full_preprocessor.named_transformers_['bin_features']['kbins'].get_feature_names_out(bin_features)\n",
    "final_feature_names = np.concatenate([poly_names, bin_names, base_num, cat_features])\n",
    "\n",
    "\n",
    "feature_file = \"feature_names_fe.txt\"\n",
    "with open(feature_file, \"w\") as f:\n",
    "    for col in final_feature_names:\n",
    "        f.write(f\"{col}\\n\")\n",
    "\n",
    "\n",
    "pipeline_fe = Pipeline([\n",
    "    (\"preprocessor\", full_preprocessor),\n",
    "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_fe.fit(X_train_fe_sklearn, y_train)\n",
    "y_pred = pipeline_fe.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\") \n",
    "mlflow.set_experiment(\"Feature_Engineering_Experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"fe_polynomial_kbins_randomforest\"):\n",
    "    mlflow.set_tag(\"task\", \"feature_engineering_with_sklearn\")\n",
    "\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    input_example = X_train.head(5)\n",
    "    signature = infer_signature(X_train.head(5), pipeline_fe.predict(X_train.head(5)))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline_fe,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    mlflow.log_artifact(feature_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Новые признаки и замена первоначальной трансформации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: autofeat\n",
      "Version: 2.1.3\n",
      "Summary: Automatic Feature Engineering and Selection Linear Prediction Model\n",
      "Home-page: https://franziskahorn.de/autofeat\n",
      "Author: Franziska Horn\n",
      "Author-email: cod3licious@gmail.com\n",
      "License: MIT\n",
      "Location: /Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages\n",
      "Requires: numba, scikit-learn, sympy, joblib, pint, scipy, pandas, numpy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show autofeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[featsel] Scaling data.../            406 feature tuples combineddone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]     9/   10 new features\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025/04/10 18:32:48 INFO mlflow.tracking.fluent: Experiment with name 'AutoFeat_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]     9/   10 new features\r"
     ]
    }
   ],
   "source": [
    "from autofeat import AutoFeatRegressor\n",
    "\n",
    "X_train_fe_autofeat = X_train.copy() # делаем одинаково как и в пред пункте\n",
    "cat_features = ['Fuel_Type', 'Selling_type', 'Transmission']\n",
    "encoder = ColumnTransformer([\n",
    "    (\"categorical\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_features)\n",
    "], remainder=\"passthrough\")\n",
    "X_train_enc = pd.DataFrame(\n",
    "    encoder.fit_transform(X_train_fe_autofeat),\n",
    "    columns=cat_features + [col for col in X_train.columns if col not in cat_features]\n",
    ")\n",
    "X_test_enc = pd.DataFrame(\n",
    "    encoder.transform(X_test),\n",
    "    columns=cat_features + [col for col in X_test.columns if col not in cat_features]\n",
    ")\n",
    "autofeat_model = AutoFeatRegressor(verbose=1, feateng_steps=2)\n",
    "\n",
    "X_train_autofeat = autofeat_model.fit_transform(X_train_enc, y_train)\n",
    "X_test_autofeat = autofeat_model.transform(X_test_enc)\n",
    "autofeat_feature_file = \"autofeat_feature_names.txt\"\n",
    "with open(autofeat_feature_file, \"w\") as f:\n",
    "    for name in X_train_autofeat.columns:\n",
    "        f.write(f\"{name}\\n\")\n",
    "pipeline_autofeat = Pipeline([\n",
    "    (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "pipeline_autofeat.fit(X_train_autofeat, y_train)\n",
    "y_pred = pipeline_autofeat.predict(X_test_autofeat)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\") \n",
    "mlflow.set_experiment(\"AutoFeat_Experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"autofeat_feateng_v2_rf\"):\n",
    "    mlflow.set_tag(\"model_type\", \"autofeat + RF\")\n",
    "    mlflow.set_tag(\"feature_engineering\", \"autofeat\")\n",
    "\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    signature = infer_signature(X_train_autofeat, y_pred)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline_autofeat,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train_autofeat.iloc[:5]\n",
    "    )\n",
    "\n",
    "    mlflow.log_artifact(autofeat_feature_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**С использованием библиотеки mlxtend отобрать N наиболее важных признаков. N выбирается с учетом количества признаков на предыдущем шаге, ориентировочный диапазон - от 20% до 70%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "2025/04/10 20:10:28 INFO mlflow.tracking.fluent: Experiment with name 'Feature_Selection_Experiment' does not exist. Creating a new experiment.\n",
      "2025/04/10 20:10:29 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      -0.1309703640428355,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.1309703640428355,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.48874306581838584,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.48874306581838584,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -1.2042884693694866,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: X has 6 features, but ColumnTransformer is expecting 7 features as input.\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "n_features_to_select = int(len(final_feature_names) * 0.5)  # 50% от признаков\n",
    "\n",
    "\n",
    "sfs_forward = SFS(\n",
    "    estimator=LinearRegression(),\n",
    "    k_features=n_features_to_select,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# признаки после fit_transform из пункта 10 нашей лр\n",
    "sfs_forward.fit(X_train_fe_transformed, y_train)\n",
    "\n",
    "selected_idx_forward = list(sfs_forward.k_feature_idx_)\n",
    "selected_names_forward = [final_feature_names[i] for i in selected_idx_forward]\n",
    "\n",
    "with open(\"sfs_forward_feature_names.txt\", \"w\") as f:\n",
    "    for name in selected_names_forward:\n",
    "        f.write(f\"{name}\\n\")\n",
    "\n",
    "with open(\"sfs_forward_feature_idx.txt\", \"w\") as f:\n",
    "    for idx in selected_idx_forward:\n",
    "        f.write(f\"{idx}\\n\")\n",
    "\n",
    "def select_features_forward(X):\n",
    "    return X[:, selected_idx_forward]\n",
    "\n",
    "feature_selector_forward = FunctionTransformer(select_features_forward)\n",
    "\n",
    "pipeline_sfs_forward = Pipeline([\n",
    "    (\"preprocessor\", full_preprocessor),  # тот же, что в п.10\n",
    "    (\"select\", feature_selector_forward), # отбор признаков\n",
    "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "pipeline_sfs_forward.fit(X_train_fe_sklearn, y_train)\n",
    "y_pred = pipeline_sfs_forward.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"Feature_Selection_Experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"sfs_forward_rf\"):\n",
    "    mlflow.set_tag(\"feature_selection\", \"SFS forward\")\n",
    "    mlflow.set_tag(\"selected_features\", str(len(selected_idx_forward)))\n",
    "    mlflow.set_tag(\"base_features\", str(len(final_feature_names)))\n",
    "\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    # лог модели\n",
    "    signature = infer_signature(X_train_fe_transformed[:, selected_idx_forward], y_pred)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline_sfs_forward,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train_fe_transformed[:5, selected_idx_forward]\n",
    "    )\n",
    "\n",
    "    # лог файлов\n",
    "    mlflow.log_artifact(\"sfs_forward_feature_names.txt\")\n",
    "    mlflow.log_artifact(\"sfs_forward_feature_idx.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**повтор предыдущего действия с SequentialFeatureSelector последовательно удаляя признаки (forward=False), и\\или с помощью RFE из sklearn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Совпадающие признаки (пересечение): ['Car_depreciation_1.0', 'Car_depreciation_0.0', 'Selling_type']\n",
      "Объединённые признаки (union): ['Driven_kms Age_of_car', 'Selling_type', 'Car_depreciation_2.0', 'Car_depreciation_0.0', 'Car_depreciation_3.0', 'Age_of_car^2', 'Car_depreciation_1.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "2025/04/10 20:16:43 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      -0.21725804671643173,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.21725804671643173,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.5024092330317483,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.5024092330317483,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      -0.9912398381437197,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: X has 5 features, but ColumnTransformer is expecting 7 features as input.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "n_features_to_select_back = int(len(final_feature_names) * 0.4)  # например 40% теперь поставим\n",
    "sfs_backward = SFS(\n",
    "    estimator=LinearRegression(),\n",
    "    k_features=n_features_to_select_back,\n",
    "    forward=False,\n",
    "    floating=False,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "sfs_backward.fit(X_train_fe_transformed, y_train)\n",
    "\n",
    "selected_idx_back = list(sfs_backward.k_feature_idx_)\n",
    "selected_names_back = [final_feature_names[i] for i in selected_idx_back]\n",
    "\n",
    "with open(\"sfs_backward_feature_names.txt\", \"w\") as f:\n",
    "    for name in selected_names_back:\n",
    "        f.write(f\"{name}\\n\")\n",
    "\n",
    "with open(\"sfs_backward_feature_idx.txt\", \"w\") as f:\n",
    "    for idx in selected_idx_back:\n",
    "        f.write(f\"{idx}\\n\")\n",
    "\n",
    "\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=n_features_to_select_back)\n",
    "rfe.fit(X_train_fe_transformed, y_train)\n",
    "\n",
    "rfe_selected_idx = np.where(rfe.support_)[0].tolist()\n",
    "rfe_selected_names = [final_feature_names[i] for i in rfe_selected_idx]\n",
    "\n",
    "with open(\"rfe_feature_names.txt\", \"w\") as f:\n",
    "    for name in rfe_selected_names:\n",
    "        f.write(f\"{name}\\n\")\n",
    "\n",
    "with open(\"rfe_feature_idx.txt\", \"w\") as f:\n",
    "    for idx in rfe_selected_idx:\n",
    "        f.write(f\"{idx}\\n\")\n",
    "\n",
    "intersection = list(set(selected_names_back) & set(rfe_selected_names))\n",
    "union = list(set(selected_names_back) | set(rfe_selected_names))\n",
    "\n",
    "print(\"Совпадающие признаки (пересечение):\", intersection)\n",
    "print(\"Объединённые признаки (union):\", union)\n",
    "\n",
    "def select_features_back(X):\n",
    "    return X[:, selected_idx_back]\n",
    "\n",
    "pipeline_sfs_back = Pipeline([\n",
    "    (\"preprocessor\", full_preprocessor),\n",
    "    (\"select\", FunctionTransformer(select_features_back)),\n",
    "    (\"regressor\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_sfs_back.fit(X_train_fe_sklearn, y_train)\n",
    "y_pred = pipeline_sfs_back.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"Feature_Selection_Experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"sfs_backward_rf\"):\n",
    "    mlflow.set_tag(\"feature_selection\", \"SFS backward\")\n",
    "    mlflow.set_tag(\"selected_features\", str(len(selected_idx_back)))\n",
    "    mlflow.set_tag(\"base_features\", str(len(final_feature_names)))\n",
    "\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    signature = infer_signature(X_train_fe_transformed[:, selected_idx_back], y_pred)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline_sfs_back,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train_fe_transformed[:5, selected_idx_back]\n",
    "    )\n",
    "\n",
    "    mlflow.log_artifact(\"sfs_backward_feature_names.txt\")\n",
    "    mlflow.log_artifact(\"sfs_backward_feature_idx.txt\")\n",
    "    mlflow.log_artifact(\"rfe_feature_names.txt\")\n",
    "    mlflow.log_artifact(\"rfe_feature_idx.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**У Random Forest будем настраивать параметры**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-04-10 21:18:05,013] A new study created in memory with name: no-name-567ee764-9018-46e5-bdab-3f3fc01efac2\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,109] Trial 0 finished with value: 0.383234973547487 and parameters: {'n_estimators': 144, 'max_depth': 15, 'max_features': 0.7587945476302645}. Best is trial 0 with value: 0.383234973547487.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,200] Trial 1 finished with value: 0.4055432516313216 and parameters: {'n_estimators': 200, 'max_depth': 5, 'max_features': 0.2403950683025824}. Best is trial 0 with value: 0.383234973547487.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,242] Trial 2 finished with value: 0.3765577053435806 and parameters: {'n_estimators': 64, 'max_depth': 14, 'max_features': 0.6410035105688879}. Best is trial 2 with value: 0.3765577053435806.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,383] Trial 3 finished with value: 0.45778036654871973 and parameters: {'n_estimators': 227, 'max_depth': 3, 'max_features': 0.9729188669457949}. Best is trial 2 with value: 0.3765577053435806.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,494] Trial 4 finished with value: 0.4048713163686524 and parameters: {'n_estimators': 258, 'max_depth': 5, 'max_features': 0.26364247048639056}. Best is trial 2 with value: 0.3765577053435806.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,541] Trial 5 finished with value: 0.37441173382667103 and parameters: {'n_estimators': 96, 'max_depth': 6, 'max_features': 0.5722807884690141}. Best is trial 5 with value: 0.37441173382667103.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,614] Trial 6 finished with value: 0.3743995653601319 and parameters: {'n_estimators': 158, 'max_depth': 6, 'max_features': 0.6506676052501416}. Best is trial 6 with value: 0.3743995653601319.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,657] Trial 7 finished with value: 0.371005972112179 and parameters: {'n_estimators': 85, 'max_depth': 6, 'max_features': 0.4297256589643225}. Best is trial 7 with value: 0.371005972112179.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,734] Trial 8 finished with value: 0.37903358032750534 and parameters: {'n_estimators': 164, 'max_depth': 13, 'max_features': 0.2797064039425238}. Best is trial 7 with value: 0.371005972112179.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,816] Trial 9 finished with value: 0.384358224473788 and parameters: {'n_estimators': 179, 'max_depth': 10, 'max_features': 0.14180537144799796}. Best is trial 7 with value: 0.371005972112179.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,874] Trial 10 finished with value: 0.37480835629650333 and parameters: {'n_estimators': 102, 'max_depth': 9, 'max_features': 0.41814448809235194}. Best is trial 7 with value: 0.371005972112179.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,938] Trial 11 finished with value: 0.3756502932406575 and parameters: {'n_estimators': 122, 'max_depth': 8, 'max_features': 0.4490856528290645}. Best is trial 7 with value: 0.371005972112179.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:05,973] Trial 12 finished with value: 0.38291260661289384 and parameters: {'n_estimators': 53, 'max_depth': 7, 'max_features': 0.7701948095056621}. Best is trial 7 with value: 0.371005972112179.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:06,097] Trial 13 finished with value: 0.47078221694422134 and parameters: {'n_estimators': 292, 'max_depth': 3, 'max_features': 0.46591877453551533}. Best is trial 7 with value: 0.371005972112179.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:18:06,166] Trial 14 finished with value: 0.3791199207156188 and parameters: {'n_estimators': 139, 'max_depth': 5, 'max_features': 0.6861505679787653}. Best is trial 7 with value: 0.371005972112179.\n",
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "2025/04/10 21:18:06 INFO mlflow.tracking.fluent: Experiment with name 'Hyperparameter_Tuning_RF' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 85, 'max_depth': 6, 'max_features': 0.4297256589643225}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'BaselineRandomForest' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'BaselineRandomForest'.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 4929.50it/s] \n",
      "2025/04/10 21:18:07 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      -0.1309703640428355,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.1309703640428355,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.48874306581838584,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -0.48874306581838584,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -1.2042884693694866,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      2.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: X has 6 features, but ColumnTransformer is expecting 7 features as input.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# j,thnrf для обучения и оценки модели\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    max_features = trial.suggest_float(\"max_features\", 0.1, 1.0)\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"preprocessor\", full_preprocessor),\n",
    "        (\"select\", FunctionTransformer(select_features_forward)),\n",
    "        (\"regressor\", RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            max_features=max_features,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train_fe_sklearn, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    return mae  # минимизируем\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Лучшие параметры:\", best_params)\n",
    "\n",
    "\n",
    "best_model = Pipeline([\n",
    "    (\"preprocessor\", full_preprocessor),\n",
    "    (\"select\", FunctionTransformer(select_features_forward)),\n",
    "    (\"regressor\", RandomForestRegressor(\n",
    "        **best_params,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "best_model.fit(X_train_fe_sklearn, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"Hyperparameter_Tuning_RF\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"rf_tuned_sfs_forward_v2\"):\n",
    "    mlflow.set_tag(\"model_type\", \"RandomForest tuned\")\n",
    "    mlflow.set_tag(\"tuning\", \"optuna\")\n",
    "    mlflow.set_tag(\"selected_features\", str(len(selected_idx_forward)))\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    signature = infer_signature(X_train_fe_transformed[:, selected_idx_forward], y_pred)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=best_model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train_fe_transformed[:5, selected_idx_forward],\n",
    "        registered_model_name=\"BaselineRandomForest\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[featsel] Scaling data...done.        406 feature tuples combined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]     9/   10 new features\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-04-10 21:34:45,393] A new study created in memory with name: no-name-a60ddea5-8b37-41f9-8e93-d36df84ecfc8\n",
      "[I 2025-04-10 21:34:45,510] Trial 0 finished with value: 0.28826068216418577 and parameters: {'n_estimators': 144, 'max_depth': 20, 'max_features': 0.7587945476302645}. Best is trial 0 with value: 0.28826068216418577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]     9/   10 new features\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-10 21:34:45,606] Trial 1 finished with value: 0.3104503222618805 and parameters: {'n_estimators': 200, 'max_depth': 5, 'max_features': 0.2403950683025824}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:45,654] Trial 2 finished with value: 0.2992764919781907 and parameters: {'n_estimators': 64, 'max_depth': 18, 'max_features': 0.6410035105688879}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:45,784] Trial 3 finished with value: 0.3045257146214363 and parameters: {'n_estimators': 227, 'max_depth': 3, 'max_features': 0.9729188669457949}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:45,911] Trial 4 finished with value: 0.3105702448074429 and parameters: {'n_estimators': 258, 'max_depth': 6, 'max_features': 0.26364247048639056}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:45,975] Trial 5 finished with value: 0.30469389299815836 and parameters: {'n_estimators': 96, 'max_depth': 8, 'max_features': 0.5722807884690141}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:46,085] Trial 6 finished with value: 0.2938008326554508 and parameters: {'n_estimators': 158, 'max_depth': 8, 'max_features': 0.6506676052501416}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:46,137] Trial 7 finished with value: 0.2893695047072261 and parameters: {'n_estimators': 85, 'max_depth': 8, 'max_features': 0.4297256589643225}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:46,226] Trial 8 finished with value: 0.3057520027972737 and parameters: {'n_estimators': 164, 'max_depth': 17, 'max_features': 0.2797064039425238}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:46,314] Trial 9 finished with value: 0.32119709716555184 and parameters: {'n_estimators': 179, 'max_depth': 13, 'max_features': 0.14180537144799796}. Best is trial 0 with value: 0.28826068216418577.\n",
      "[I 2025-04-10 21:34:46,423] Trial 10 finished with value: 0.2870842983862046 and parameters: {'n_estimators': 128, 'max_depth': 13, 'max_features': 0.8729510241909679}. Best is trial 10 with value: 0.2870842983862046.\n",
      "[I 2025-04-10 21:34:46,531] Trial 11 finished with value: 0.28995184594350454 and parameters: {'n_estimators': 120, 'max_depth': 20, 'max_features': 0.8834754736388984}. Best is trial 10 with value: 0.2870842983862046.\n",
      "[I 2025-04-10 21:34:46,627] Trial 12 finished with value: 0.2892775115666859 and parameters: {'n_estimators': 116, 'max_depth': 14, 'max_features': 0.8052666590341151}. Best is trial 10 with value: 0.2870842983862046.\n",
      "[I 2025-04-10 21:34:46,740] Trial 13 finished with value: 0.28661074181925456 and parameters: {'n_estimators': 139, 'max_depth': 15, 'max_features': 0.7726547685746881}. Best is trial 13 with value: 0.28661074181925456.\n",
      "[I 2025-04-10 21:34:46,860] Trial 14 finished with value: 0.2862226138091607 and parameters: {'n_estimators': 134, 'max_depth': 15, 'max_features': 0.9952889269957197}. Best is trial 14 with value: 0.2862226138091607.\n",
      "2025/04/10 21:34:46 INFO mlflow.tracking.fluent: Experiment with name 'AutoFeat_Tuned' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 134, 'max_depth': 15, 'max_features': 0.9952889269957197}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'BaselineRandomForest' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'BaselineRandomForest'.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 5192.81it/s] \n"
     ]
    }
   ],
   "source": [
    "# на предыдущем шаге некорректно сравнили метрики - теперь делаем на основе действительно лучшей модели\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from autofeat import AutoFeatRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.exceptions import RestException\n",
    "\n",
    "\n",
    "X_train_fe_autofeat = X_train.copy()\n",
    "cat_features = ['Fuel_Type', 'Selling_type', 'Transmission']\n",
    "\n",
    "encoder = ColumnTransformer([\n",
    "    (\"categorical\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_features)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "X_train_enc = pd.DataFrame(\n",
    "    encoder.fit_transform(X_train_fe_autofeat),\n",
    "    columns=cat_features + [col for col in X_train.columns if col not in cat_features]\n",
    ")\n",
    "X_test_enc = pd.DataFrame(\n",
    "    encoder.transform(X_test),\n",
    "    columns=cat_features + [col for col in X_test.columns if col not in cat_features]\n",
    ")\n",
    "\n",
    "\n",
    "autofeat_model = AutoFeatRegressor(verbose=1, feateng_steps=2)\n",
    "X_train_autofeat = autofeat_model.fit_transform(X_train_enc, y_train)\n",
    "X_test_autofeat = autofeat_model.transform(X_test_enc)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        max_features=trial.suggest_float(\"max_features\", 0.1, 1.0),\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_autofeat, y_train)\n",
    "    preds = model.predict(X_test_autofeat)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    return mae  # минимизируем!\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Лучшие параметры:\", best_params)\n",
    "\n",
    "best_model = RandomForestRegressor(**best_params, random_state=42)\n",
    "best_model.fit(X_train_autofeat, y_train)\n",
    "y_pred = best_model.predict(X_test_autofeat)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"AutoFeat_Tuned\")\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"BaselineRandomForest\"\n",
    "\n",
    "# Удалим существующую версию 2\n",
    "for mv in client.search_model_versions(f\"name='{model_name}'\"):\n",
    "    if mv.version == \"2\":\n",
    "        client.delete_model_version(name=model_name, version=2)\n",
    "\n",
    "with mlflow.start_run(run_name=\"autofeat_rf_hyperopt_v2\"):\n",
    "    mlflow.set_tag(\"model_type\", \"autofeat + RF tuned\")\n",
    "    mlflow.set_tag(\"based_on\", \"autofeat_feateng_v2_rf\")\n",
    "    mlflow.set_tag(\"tuning\", \"optuna\")\n",
    "    \n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    signature = infer_signature(X_train_autofeat, y_pred)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=best_model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=X_train_autofeat.iloc[:5],\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучить модель с помощью алгоритма CatBoost с выбранным набором признаков**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'BaselineRandomForest' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'BaselineRandomForest'.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 5435.05it/s] \n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_autofeat, y_train)\n",
    "y_pred = xgb_model.predict(X_test_autofeat)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"AutoFeat_Tuned\")\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"BaselineRandomForest\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"autofeat_xgboost_v4\"):\n",
    "    mlflow.set_tag(\"model_type\", \"autofeat + XGBoost\")\n",
    "    mlflow.set_tag(\"based_on\", \"autofeat_feateng_v2_rf\")\n",
    "    mlflow.set_tag(\"tuning\", \"manual default (xgboost)\")\n",
    "\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n",
    "    signature = infer_signature(X_train_autofeat, y_pred)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=xgb_model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=X_train_autofeat.iloc[:5],\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# По всем прогонам найдена лучшая по метрикам модель, для нее сейчас сделаем прогон на всей выборке и все залогируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergejvaresko/iis_proj/.venv_lab_iis/lib/python3.9/site-packages/autofeat/featsel.py:270: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  if np.max(np.abs(correlations[c].ravel()[:i])) < 0.9:\n",
      "2025/04/10 23:10:27 INFO mlflow.tracking.fluent: Experiment with name 'Final_Model_Training' does not exist. Creating a new experiment.\n",
      "Registered model 'BaselineRandomForest' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'BaselineRandomForest'.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 5573.30it/s] \n",
      "/var/folders/3f/x14h836923j7lv3kqcc_d9gc0000gn/T/ipykernel_86896/641021998.py:78: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1744315829377, current_stage='Production', description=None, last_updated_timestamp=1744315829436, name='BaselineRandomForest', run_id='cab059e767df4e13a49baae66fcacdad', run_link=None, source='/Users/sergejvaresko/iis_proj/research/mlruns/9/cab059e767df4e13a49baae66fcacdad/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=5>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from autofeat import AutoFeatRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "full_data = pd.concat([X_train, X_test], axis=0)\n",
    "full_target = pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "cat_features = ['Fuel_Type', 'Selling_type', 'Transmission']\n",
    "encoder = ColumnTransformer([\n",
    "    (\"categorical\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_features)\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "full_data_enc = pd.DataFrame(\n",
    "    encoder.fit_transform(full_data),\n",
    "    columns=cat_features + [col for col in full_data.columns if col not in cat_features]\n",
    ")\n",
    "\n",
    "\n",
    "autofeat_model = AutoFeatRegressor(verbose=0, feateng_steps=2)\n",
    "full_data_autofeat = autofeat_model.fit_transform(full_data_enc, full_target)\n",
    "\n",
    "\n",
    "final_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "final_model.fit(full_data_autofeat, full_target)\n",
    "\n",
    "input_example = full_data_autofeat.iloc[:5]\n",
    "signature = infer_signature(full_data_autofeat, final_model.predict(full_data_autofeat.iloc[:5]))\n",
    "\n",
    "\n",
    "features_file = \"final_autofeat_feature_names.txt\"\n",
    "with open(features_file, \"w\") as f:\n",
    "    for col in full_data_autofeat.columns:\n",
    "        f.write(f\"{col}\\n\")\n",
    "\n",
    "requirements_path = \"/Users/sergejvaresko/iis_proj/requirements.txt\"\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:////Users/sergejvaresko/iis_proj/mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"Final_Model_Training\")\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"BaselineRandomForest\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"final_autofeat_xgboost_production\"):\n",
    "    mlflow.set_tag(\"stage\", \"production-ready\")\n",
    "    mlflow.set_tag(\"based_on\", \"autofeat_xgboost_v4\")\n",
    "\n",
    "    mlflow.log_artifact(features_file)\n",
    "    mlflow.log_artifact(requirements_path)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=final_model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "\n",
    "# Обновляем stage на Production\n",
    "latest_version = max([\n",
    "    int(mv.version)\n",
    "    for mv in client.search_model_versions(f\"name='{model_name}'\")\n",
    "])\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=latest_version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_lab_iis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
